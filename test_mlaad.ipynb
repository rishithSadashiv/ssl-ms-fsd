{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from model5 import Model\n",
    "# from model4 import Model\n",
    "# from model5 import Model\n",
    "# from model6 import Model\n",
    "# from model7 import Model\n",
    "from core_scripts.startup_config import set_random_seed\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import soundfile as sf\n",
    "from evaluation import compute_eer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\n",
    "\n",
    "\n",
    "def pad_random(x: np.ndarray, max_len: int = 64600):\n",
    "    x_len = x.shape[0]\n",
    "    # if duration is already long enough\n",
    "    if x_len >= max_len:\n",
    "        stt = np.random.randint(x_len - max_len)\n",
    "        return x[stt:stt + max_len]\n",
    "\n",
    "    # if too short\n",
    "    num_repeats = int(max_len / x_len) + 1\n",
    "    padded_x = np.tile(x, (num_repeats))[:max_len]\n",
    "    return padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSpoof_list_mlaad(dir_meta, is_train=False, is_eval=False):\n",
    "\n",
    "    d_meta = {}\n",
    "    file_list = []\n",
    "    with open(dir_meta, \"r\") as f:\n",
    "        l_meta = f.readlines()\n",
    "\n",
    "    if is_train:\n",
    "        for line in l_meta:\n",
    "            key, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list\n",
    "\n",
    "    elif is_eval:\n",
    "        for line in l_meta:\n",
    "            key, _ = line.strip().split(\" \")\n",
    "            #key = line.strip()\n",
    "            file_list.append(key)\n",
    "        return file_list\n",
    "    else:\n",
    "        for line in l_meta:\n",
    "            key, label = line.strip().split(\" \")\n",
    "            file_list.append(key)\n",
    "            d_meta[key] = 1 if label == \"bonafide\" else 0\n",
    "        return d_meta, file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Dataset_mlaad_devNeval(Dataset):\n",
    "#     def __init__(self, list_IDs, base_dir):\n",
    "#         \"\"\"self.list_IDs\t: list of strings (each string: utt key),\n",
    "#         \"\"\"\n",
    "#         self.list_IDs = list_IDs\n",
    "#         self.base_dir = base_dir\n",
    "#         self.cut = 64600  # take ~4 sec audio (64600 samples)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.list_IDs)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         key = self.list_IDs[index]\n",
    "#         X, _ = sf.read(str(key))\n",
    "#         X_pad = pad(X, self.cut)\n",
    "#         x_inp = Tensor(X_pad)\n",
    "#         return x_inp, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils_SSL import getMsValues\n",
    "# class Dataset_mlaad_devNeval(Dataset):\n",
    "#     def __init__(self, list_IDs, base_dir):\n",
    "#         \"\"\"self.list_IDs\t: list of strings (each string: utt key),\n",
    "#         \"\"\"\n",
    "#         self.list_IDs = list_IDs\n",
    "#         self.base_dir = base_dir\n",
    "#         self.cut = 64600  # take ~4 sec audio (64600 samples)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.list_IDs)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         key = self.list_IDs[index]\n",
    "#         X, _ = sf.read(str(key))\n",
    "#         X_pad = pad(X, self.cut)\n",
    "#         x_inp = Tensor(X_pad)\n",
    "#         # ms_dict = getMsValues(X_pad, 16000)\n",
    "#         # ms = ms_dict['power_modulation_spectrogram'][:, :, 0]\n",
    "#         # ms_tensor = Tensor(ms)\n",
    "#         return x_inp, key\n",
    "    \n",
    "class Dataset_mlaad_devNeval(Dataset):\n",
    "    def __init__(self, list_IDs, base_dir):\n",
    "        \"\"\"self.list_IDs\t: list of strings (each string: utt key),\n",
    "        \"\"\"\n",
    "        self.list_IDs = list_IDs\n",
    "        self.base_dir = base_dir\n",
    "        self.cut = 64600  # take ~4 sec audio (64600 samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        key = self.list_IDs[index]\n",
    "        X, _ = sf.read(str(key))\n",
    "        X_pad = pad(X, self.cut)\n",
    "        x_inp = Tensor(X_pad)\n",
    "        ms_dict = getMsValues(X_pad, 16000)\n",
    "        ms = ms_dict['power_modulation_spectrogram'][:, :, 0]\n",
    "        ms_tensor = Tensor(ms)\n",
    "        return x_inp, key, ms_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    database_path = \"\"\n",
    "    protocols_path = \"database/\"\n",
    "    seed = 1234\n",
    "    track = \"LA\"\n",
    "    is_eval = True\n",
    "    cudnn_deterministic_toggle = True\n",
    "    cudnn_benchmark_toggle = False\n",
    "    # model_path = \"/DATA/Rishith/SSL_Anti-spoofing/models_mlaad/model_LA_WCE_100_14_1e-06/epoch_99.pth\"\n",
    "    \n",
    "    # model_path = \"/DATA/Rishith/SSL_Anti-spoofing/models_combined/model_LA_WCE_100_32_1e-06/epoch_70.pth\"\n",
    "    # model_path = \"/DATA/Rishith/SSL_Anti-spoofing/models5_msFusion_hdim256/model_LA_WCE_100_14_1e-06/epoch_51.pth\"\n",
    "    # model_path = \"/DATA/Rishith/SSL_Anti-spoofing/models7_msOnly_trial3/model_LA_WCE_100_14_1e-05/epoch_91.pth\"\n",
    "    # model_path = \"/DATA/Rishith/Abhishek/SSL_Anti-spoofing/pretrained_models/LA_model.pth\"\n",
    "\n",
    "    model_path = \"/DATA/Rishith/Abhishek/SSL_Anti-spoofing/models_seed=10(fusion)/model_LA_WCE_100_14_1e-06/epoch_32.pth\"\n",
    "    # eval_output = \"eval_CM_scores_file_SSL_mlaadModel_epoch99_mlaad.txt\"\n",
    "    eval_output = \"/DATA/Rishith/Abhishek/SSL_Anti-spoofing/testing_results/my_trained/my_trained_test_epoch32_new_fusion.txt\"\n",
    "    \n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(args.seed, args)\n",
    "track = args.track\n",
    "prefix      = 'ASVspoof_{}'.format(track)\n",
    "prefix_2019 = 'ASVspoof2019.{}'.format(track)\n",
    "prefix_2021 = 'ASVspoof2021.{}'.format(track)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "model = Model(args,device)\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n",
    "model =model.to(device)\n",
    "print('nb_params:',nb_params)\n",
    "\n",
    "if args.model_path:\n",
    "    model.load_state_dict(torch.load(args.model_path,map_location=device))\n",
    "    print('Model loaded : {}'.format(args.model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def produce_evaluation_file(dataset, model, device, save_path, trial_path):\n",
    "#     data_loader = DataLoader(dataset, batch_size=10, shuffle=False, drop_last=False)\n",
    "#     num_correct = 0.0\n",
    "#     num_total = 0.0\n",
    "#     model.eval()\n",
    "    \n",
    "#     fname_list = []\n",
    "#     key_list = []\n",
    "#     score_list = []\n",
    "    \n",
    "#     with open(trial_path, \"r\") as f_trl:\n",
    "#         trial_lines = f_trl.readlines()\n",
    "    \n",
    "#     for batch_x,utt_id, _ in data_loader:\n",
    "#         batch_x = batch_x.to(device)\n",
    "#         with torch.no_grad():\n",
    "#             batch_out = model(batch_x)\n",
    "#             batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "#         # add outputs\n",
    "#         fname_list.extend(utt_id)\n",
    "#         score_list.extend(batch_score.tolist())\n",
    "    \n",
    "#     assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "#     with open(save_path, \"w\") as fh:\n",
    "#         for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "#             utt_id, key = trl.strip().split(' ')\n",
    "#             assert fn == utt_id\n",
    "#             fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))\n",
    "#     print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def produce_evaluation_file(dataset, model, device, save_path, trial_path):\n",
    "    # data_loader = DataLoader(dataset, batch_size=10, shuffle=False, drop_last=False)\n",
    "    data_loader = DataLoader(dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "    num_correct = 0.0\n",
    "    num_total = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    fname_list = []\n",
    "    key_list = []\n",
    "    score_list = []\n",
    "    \n",
    "    with open(trial_path, \"r\") as f_trl:\n",
    "        trial_lines = f_trl.readlines()\n",
    "    \n",
    "    for batch_x,utt_id, ms in data_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        ms = ms.to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_out = model(batch_x, ms)\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "    \n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "    with open(save_path, \"w\") as fh:\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "            utt_id, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            fh.write(\"{} {} {}\\n\".format(utt_id, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_database_path = \"\"\n",
    "eval_trial_path = os.path.join(args.protocols_path+\"mlaad_protocols/fsd_test_protocol.txt\")\n",
    "file_eval = genSpoof_list_mlaad( dir_meta =  eval_trial_path,is_train=False,is_eval=True)\n",
    "print('no. of eval trials',len(file_eval))\n",
    "eval_set=Dataset_mlaad_devNeval(list_IDs = file_eval,base_dir = eval_database_path)\n",
    "# produce_evaluation_file(eval_set, model, device, args.eval_output, eval_trial_path)\n",
    "produce_evaluation_file(eval_set, model, device, args.eval_output, eval_trial_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tDCF_EER(cm_scores_file):\n",
    "    \n",
    "    \n",
    "    # Load CM scores\n",
    "    cm_data = np.genfromtxt(cm_scores_file, dtype=str)\n",
    "    # cm_utt_id = cm_data[:, 0]\n",
    "    # cm_sources = cm_data[:, 1]\n",
    "    \n",
    "    cm_keys = cm_data[:, 1]\n",
    "    cm_scores = cm_data[:, 2].astype(float)\n",
    "\n",
    "    # Extract bona fide (real human) and spoof scores from the CM scores\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "\n",
    "    eer_cm = compute_eer(bona_cm, spoof_cm)[0]\n",
    "\n",
    "    min_tDCF = 0\n",
    "\n",
    "\n",
    "\n",
    "    return eer_cm * 100, min_tDCF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_eer, eval_tdcf = calculate_tDCF_EER(cm_scores_file=args.eval_output)\n",
    "print(eval_eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import compute_eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_score_path = \"scores_output/eval_CM_scores_file_SSL_msFusion_hdim256_combinedModel_epoch25_mlaad.txt\"\n",
    "# eval_score_path = \"scores_output/eval_CM_scores_file_SSL_msFusion_hdim256_epoch51_mlaad_new.txt\"\n",
    "eval_score_path = \"/DATA/Rishith/Abhishek/SSL_Anti-spoofing/testing_results/my_trained/my_trained_test_epoch32_mlaad.txt\"\n",
    "# eval_score_path = args.eval_output\n",
    "cm_data = np.genfromtxt(eval_score_path, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_keys = cm_data[:, 1]\n",
    "cm_scores = cm_data[:, 2].astype(float)\n",
    "bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "\n",
    "print(\"Size of bona_cm:\", bona_cm.shape)\n",
    "print(\"Size of spoof_cm:\", spoof_cm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_data[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_data[-1,0].split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eer_cm, th = compute_eer(bona_cm, spoof_cm)\n",
    "print(eer_cm* 100)\n",
    "print(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eer_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(bona_cm,200)\n",
    "plt.hist(spoof_cm,200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.hist(bona_cm,200, color='blue')\n",
    "plt.xlim(-6,6)\n",
    "plt.ylim(0,500)\n",
    "plt.subplot(212)\n",
    "plt.hist(spoof_cm,200, color='orange')\n",
    "plt.xlim(-6,6)\n",
    "# plt.ylim(0,500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
